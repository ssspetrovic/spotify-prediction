{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Song Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ucitavanje biblioteka i funkcija\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spotify_songs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping invalid and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['track_id', 'track_artist', 'track_name', 'track_album_id', 'track_album_name', 'playlist_name', 'playlist_id']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "rows_to_drop = df.loc[df['duration_ms'] < 20000].index\n",
    "df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "new_df = df.copy()\n",
    "\n",
    "# Assuming 'date' is a string column in the format 'YYYY-MM-DD'\n",
    "new_df[['year', 'month', 'day']] = new_df['track_album_release_date'].str.split('-', expand=True)\n",
    "\n",
    "# Convert the columns to numeric (to handle missing values during median calculation)\n",
    "new_df['year'] = pd.to_numeric(new_df['year'], errors='coerce', downcast='integer')\n",
    "# new_df['month'] = pd.to_numeric(new_df['month'], errors='coerce', downcast='integer')\n",
    "# new_df['day'] = pd.to_numeric(new_df['day'], errors='coerce', downcast='integer')\n",
    "\n",
    "# Calculate median values for year, month, and day\n",
    "median_year = int(new_df['year'].median())\n",
    "# median_month = int(new_df['month'].median())\n",
    "# median_day = int(new_df['day'].median())\n",
    "\n",
    "# Fill missing values with median values\n",
    "new_df['year'] = new_df['year'].fillna(median_year).astype(int)\n",
    "# new_df['month'] = new_df['month'].fillna(median_month).astype(int)\n",
    "# new_df['day'] = new_df['day'].fillna(median_day).astype(int)\n",
    "\n",
    "X = new_df.drop(['track_popularity', 'track_album_release_date'], axis=1)\n",
    "X = pd.get_dummies(X, dtype=int)\n",
    "y = new_df['track_popularity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.tail()\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3446]\n",
    "X.iloc[3446]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns)\n",
    "\n",
    "numeric_feats = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "dummy_feats = [feat for feat in X.columns if feat not in numeric_feats]\n",
    "\n",
    "print(X[numeric_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_values = df[numeric_feats]\n",
    "correlation_matrix = numeric_values.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_test, y_predicted, N, d):\n",
    "    mse = mean_squared_error(y_test, y_predicted)\n",
    "    mae = mean_absolute_error(y_test, y_predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_predicted)\n",
    "    r2_adj = 1 - ((1 - r2) * (N - 1)) / (N - d - 1)\n",
    "\n",
    "    # printing values\n",
    "    print('Mean squared error: ', mse)\n",
    "    print('Mean absolute error: ', mae)\n",
    "    print('Root mean squared error: ', rmse)\n",
    "    print('R2 score: ', r2)\n",
    "    print('R2 adjusted score: ', r2_adj)\n",
    "\n",
    "    # Uporedni prikaz nekoliko pravih i predvidjenih vrednosti\n",
    "    res = pd.concat([pd.DataFrame(y_test.values),\n",
    "                    pd.DataFrame(y_predicted)], axis=1)\n",
    "    res.columns = ['y', 'y_pred']\n",
    "    print(res.head(20))\n",
    "    return mse, mae, rmse, r2, r2_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "s.fit(X_train[numeric_feats])\n",
    "X_train_std = s.transform(X_train[numeric_feats])\n",
    "X_test_std = s.transform(X_test[numeric_feats])\n",
    "X_train_std = pd.DataFrame(X_train_std)\n",
    "X_test_std = pd.DataFrame(X_test_std)\n",
    "\n",
    "\n",
    "X_train_std = pd.concat([X_train_std, X_train[dummy_feats].reset_index(drop=True)], axis=1)\n",
    "X_test_std = pd.concat([X_test_std, X_test[dummy_feats].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_std.columns = list(X.columns)\n",
    "X_test_std.columns = list(X.columns)\n",
    "X_train_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 16))}]\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "rfe = RFE(lm)\n",
    "\n",
    "model_cv = GridSearchCV(\n",
    "    estimator=rfe,\n",
    "    param_grid=hyper_params,\n",
    "    scoring='r2',\n",
    "    cv=folds,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting cv results\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('r-squared')\n",
    "plt.title(\"Optimal Number of Features\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal number of features is 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model\n",
    "n_features_optimal = 13\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "rfe = RFE(lm, n_features_to_select=n_features_optimal)             \n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "# predict prices of X_test\n",
    "y_pred = lm.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(r2)\n",
    "print(mse)\n",
    "\n",
    "#model_evaluation(y_test, y_pred, X_train.shape[0], X_train.shape[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
